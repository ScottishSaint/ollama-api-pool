{
  "name": "ollama-api-pool",
  "version": "2.0.0",
  "description": "ðŸš€ åŸºäºŽ Cloudflare Workers çš„ Ollama API ä»£ç†æ±  - æ”¯æŒå¤šè´¦å·è½®è¯¢ã€è‡ªåŠ¨æ•…éšœè½¬ç§»ã€è´Ÿè½½å‡è¡¡å’Œç»Ÿä¸€é‰´æƒã€‚é«˜å¯ç”¨ã€è¾¹ç¼˜è®¡ç®—ã€OpenAI å…¼å®¹çš„ AI æ¨¡åž‹ API ç½‘å…³ã€‚",
  "main": "src/index.js",
  "type": "module",
  "scripts": {
    "deploy": "wrangler deploy",
    "dev": "wrangler dev",
    "tail": "wrangler tail",
    "publish": "wrangler deploy --env production"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/dext7r/ollama-api-pool.git"
  },
  "keywords": [
    "ollama",
    "ollama-api",
    "api-pool",
    "api-gateway",
    "api-proxy",
    "load-balancer",
    "load-balancing",
    "fault-tolerance",
    "high-availability",
    "cloudflare",
    "cloudflare-workers",
    "workers",
    "serverless",
    "edge-computing",
    "openai-compatible",
    "llm",
    "llm-api",
    "ai",
    "ai-gateway",
    "machine-learning",
    "ml",
    "artificial-intelligence",
    "api-management",
    "api-authentication",
    "round-robin",
    "health-check",
    "analytics"
  ],
  "author": {
    "name": "dext7r",
    "email": "h7ml@qq.com",
    "url": "https://github.com/dext7r"
  },
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/dext7r/ollama-api-pool/issues"
  },
  "homepage": "https://ollama-api-pool.h7ml.workers.dev",
  "documentation": "https://ollama-api-pool.h7ml.workers.dev/api-docs",
  "demo": "https://ollama-api-pool.h7ml.workers.dev",
  "engines": {
    "node": ">=20.0.0",
    "pnpm": ">=8.0.0"
  },
  "packageManager": "pnpm@8.15.0",
  "dependencies": {
    "wrangler": "^4.42.1"
  },
  "funding": {
    "type": "github",
    "url": "https://github.com/sponsors/dext7r"
  }
}
